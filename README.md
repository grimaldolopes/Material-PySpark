# Sobre PySpark

Vamos entender que o PySpark é uma API Python para Apache SPARK que é denominado como o mecanismo de processamento analítico para aplicações de processamento de dados distribuídos em larga escala e aprendizado de máquina, ou seja, para grandes volumes de dados.

O uso da biblioteca Pyspark possui diversas vantagens:

• É um mecanismo de processamento distribuído , na memória, que permite o processamento de dados de forma eficiente e de características distribuída.

• Com o uso do PySpark, é possível o processamento de dados em Hadoop (HDFS), AWS S3 e outros sistemas de arquivos.

• Possui bibliotecas de aprendizado de máquina e gráficos.

• Geralmente as aplicações criadas e executadas no PySpark são 100x mais rápidas que outras em sistemas de dados conhecidos. 

Toda a execução dos scripts são realizados dentro do Apache Spark, que distribui o processamento dentro de um ambiente de cluster que são interligados aos NÓS que realizam a execução e transformação dos dados.

Abrange os seguintes módulos do PySpark:

• PySpark RDD

• PySpark DataFrame and SQL

• PySpark Streaming

